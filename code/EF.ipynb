{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79997a1a-587e-498f-b9e4-ed817fe2c99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from sklearn.metrics import mean_squared_error, r2_score, balanced_accuracy_score, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from CGRtools import RDFRead\n",
    "from CGRtools.files import RDFWrite\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a86770f9-5f82-4b17-bbc4-8bd553b0073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('results/selected_datasets.pickle', 'rb') as f:\n",
    "    selected_datasets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2795baca-b477-44fc-976f-abe384cdcbd6",
   "metadata": {},
   "source": [
    "КЛАССИФИКАЦИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4983a2e3-6c5c-40cd-8e59-38fdf0c5ac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EF_classification(dataset, method):\n",
    "    data = []\n",
    "    with open(f'x_and_y/{dataset}.pickle', \"rb\") as f:\n",
    "        for _ in range(pickle.load(f)):\n",
    "            data.append(pickle.load(f))   \n",
    "    x_train_ex, x_test_ex, y_test_ex_regr, y_train_ex, y_test_ex = data[0], data[1], data[3], data[4], data[5]\n",
    "    x_train_in, x_test_in, y_train_in, y_test_in = train_test_split(x_train_ex, y_train_ex, test_size=len(y_train_ex)-10)\n",
    "    results = []\n",
    "    iteration = 0\n",
    "    while y_train_in.shape[0] < y_train_ex.shape[0]:\n",
    "        \n",
    "        rfc = RandomForestClassifier(random_state=42, n_estimators=500, max_features='log2', n_jobs=20)\n",
    "        rfc.fit(x_train_in.values, y_train_in['activity'].values)\n",
    "        classes = set(y_train_in['activity'].values)\n",
    " \n",
    "        probs = rfc.predict_proba(x_test_in.values)\n",
    "        probs_difference, prob_of_label_1, prob_bernulli = [], [], []\n",
    "        for n, prob in enumerate(probs):\n",
    "            try:\n",
    "                prob_bernulli.append([x_test_in.index[n], prob[1]*(1-prob[1])])\n",
    "                probs_difference.append([x_test_in.index[n], abs(prob[0]-prob[1])])\n",
    "                prob_of_label_1.append([x_test_in.index[n], prob[1]])\n",
    "            except IndexError:\n",
    "                probs_difference.append([x_test_in.index[n], 1])\n",
    "                prob_bernulli.append([x_test_in.index[n], 0])\n",
    "                if 1 in classes:\n",
    "                    prob_of_label_1.append([x_test_in.index[n], 1]) \n",
    "                else:\n",
    "                    prob_of_label_1.append([x_test_in.index[n], 0])\n",
    "\n",
    "        least_sure = [x[0] for x in sorted(probs_difference, key=lambda x: x[1], reverse=False)][:5]\n",
    "        most_sure = [x[0] for x in sorted(prob_of_label_1, key=lambda x: x[1], reverse=True)][:5]\n",
    "        least_sure_bernulli = [x[0] for x in sorted(prob_bernulli, key=lambda x: x[1], reverse=True)][:5]\n",
    "\n",
    "\n",
    "        if method == 'exploration':\n",
    "            adding_points = least_sure\n",
    "        elif method == 'exploitation':\n",
    "            adding_points = most_sure\n",
    "        elif method == 'bernulli':\n",
    "            adding_points = least_sure_bernulli\n",
    "        else:\n",
    "            try:\n",
    "                adding_points = random.sample(list(x_test_in.index), 5)\n",
    "            except ValueError:\n",
    "                adding_points = list(x_test_in.index)\n",
    "        \n",
    "        for point in adding_points:\n",
    "            x_train_in, y_train_in = x_train_in.append(x_test_in.loc[point]), y_train_in.append(y_test_in.loc[point])\n",
    "            x_test_in, y_test_in = x_test_in.drop(point), y_test_in.drop(point)\n",
    "\n",
    "        pred_ex = rfc.predict(x_test_ex.values)\n",
    "        proba_ex = rfc.predict_proba(x_test_ex.values)\n",
    "        if len(classes) == 1:\n",
    "            if 1 in classes:\n",
    "                proba_ex = np.insert(proba_ex, 0, 0, axis = 1)\n",
    "            else:\n",
    "                proba_ex = np.insert(proba_ex, 1, 0, axis = 1)\n",
    "\n",
    "        prob_of_label_1_test = []\n",
    "        for n, prob in enumerate(proba_ex):\n",
    "            prob_of_label_1_test.append([x_test_ex.index[n], prob[1]])\n",
    "\n",
    "       \n",
    "        ordered_probs = dict()\n",
    "        ranked_probs = rankdata(prob_of_label_1_test, method='dense', axis=0)\n",
    "        max_rank = np.amax(ranked_probs, axis = 0)[1]\n",
    "        for i in ranked_probs:\n",
    "            i[1] = max_rank - i[1]\n",
    "       \n",
    "        for n, el in enumerate(prob_of_label_1_test):\n",
    "            ordered_probs[el[0]] = ranked_probs[n][1]\n",
    "     \n",
    "        number_of_points = 0\n",
    "        for rank in range (max(list(ordered_probs.values()))):\n",
    "            while number_of_points < round(y_test_ex.shape[0] * 0.1):\n",
    "                number_of_points += list(ordered_probs.values()).count(rank)\n",
    "                max_rank = rank \n",
    "                break        \n",
    "      \n",
    "        predicted_max_pki = set()\n",
    "        for key, item in ordered_probs.items():\n",
    "            if item <= max_rank:\n",
    "                predicted_max_pki.add(key)\n",
    "       \n",
    "        true_max_pki = set(y_test_ex_regr.sort_values(by = 'pKi', ascending=False).index[:number_of_points])\n",
    "       \n",
    "        try:\n",
    "            results.append([iteration, len(true_max_pki.intersection(predicted_max_pki))/number_of_points, number_of_points/y_test_ex.shape[0]])\n",
    "        except ZeroDivisionError:\n",
    "            results.append([iteration, 0, number_of_points/y_test_ex.shape[0]])\n",
    "       \n",
    "\n",
    "        iteration += 1 \n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "40a53d26-784c-4880-84ad-6da7a838672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EF_new_func(dataset, method, c):\n",
    "    data = []\n",
    "    try:\n",
    "        with open(f'x_and_y/{dataset}.pickle', \"rb\") as f:\n",
    "            for _ in range(pickle.load(f)):\n",
    "                data.append(pickle.load(f))\n",
    "    except FileNotFoundError:\n",
    "        with open(f'x_and_y/{dataset}_worst.pickle', \"rb\") as f:\n",
    "            for _ in range(pickle.load(f)):\n",
    "                data.append(pickle.load(f))\n",
    "    x_train_ex, x_test_ex, y_test_ex_regr, y_train_ex, y_test_ex = data[0], data[1], data[3], data[4], data[5]\n",
    "    x_train_in, x_test_in, y_train_in, y_test_in = train_test_split(x_train_ex, y_train_ex, test_size=len(y_train_ex)-10)\n",
    "    results = []\n",
    "    iteration = 0\n",
    "    while y_train_in.shape[0] < y_train_ex.shape[0]:\n",
    "        \n",
    "        rfc = RandomForestClassifier(random_state=42, n_estimators=500, max_features='log2', n_jobs=20)\n",
    "        rfc.fit(x_train_in.values, y_train_in['activity'].values)\n",
    "        classes = set(y_train_in['activity'].values)\n",
    " \n",
    "        probs = rfc.predict_proba(x_test_in.values)\n",
    "        probs_difference_with_05, abs_value, squared_value = [], [], []\n",
    "        if len(classes) == 1:\n",
    "            if 1 in classes:\n",
    "                probs = np.insert(probs, 0, 0, axis = 1)\n",
    "            else:\n",
    "                probs = np.insert(probs, 1, 0, axis = 1)\n",
    "        for n, prob in enumerate(probs):                \n",
    "                probs_difference_with_05.append([x_test_in.index[n], prob[1] - 0.5])\n",
    "\n",
    "        for diff in probs_difference_with_05:\n",
    "\n",
    "            abs_value.append([diff[0], abs(diff[1]) - c*diff[1]])\n",
    "            squared_value.append([diff[0], diff[1]**2 - c*diff[1]])\n",
    "\n",
    "        if method == 'abs':\n",
    "            adding_points = [x[0] for x in sorted(abs_value, key=lambda x: x[1], reverse=False)][:5]\n",
    "        elif method == 'squared':\n",
    "            adding_points = [x[0] for x in sorted(squared_value, key=lambda x: x[1], reverse=False)][:5]\n",
    "\n",
    "\n",
    "        for point in adding_points:\n",
    "            x_train_in, y_train_in = x_train_in.append(x_test_in.loc[point]), y_train_in.append(y_test_in.loc[point])\n",
    "            x_test_in, y_test_in = x_test_in.drop(point), y_test_in.drop(point)\n",
    "        pred_ex = rfc.predict(x_test_ex.values)\n",
    "        proba_ex = rfc.predict_proba(x_test_ex.values)\n",
    "        if len(classes) == 1:\n",
    "            if 1 in classes:\n",
    "                proba_ex = np.insert(proba_ex, 0, 0, axis = 1)\n",
    "            else:\n",
    "                proba_ex = np.insert(proba_ex, 1, 0, axis = 1)\n",
    "\n",
    "        prob_of_label_1_test = []\n",
    "        for n, prob in enumerate(proba_ex):\n",
    "            prob_of_label_1_test.append([x_test_ex.index[n], prob[1]])\n",
    "\n",
    "       \n",
    "        ordered_probs = dict()\n",
    "        ranked_probs = rankdata(prob_of_label_1_test, method='dense', axis=0)\n",
    "        max_rank = np.amax(ranked_probs, axis = 0)[1]\n",
    "        for i in ranked_probs:\n",
    "            i[1] = max_rank - i[1]\n",
    "       \n",
    "        for n, el in enumerate(prob_of_label_1_test):\n",
    "            ordered_probs[el[0]] = ranked_probs[n][1]\n",
    "     \n",
    "        number_of_points = 0\n",
    "        for rank in range (max(list(ordered_probs.values()))):\n",
    "            while number_of_points < round(y_test_ex.shape[0] * 0.1):\n",
    "                number_of_points += list(ordered_probs.values()).count(rank)\n",
    "                max_rank = rank \n",
    "                break\n",
    "        \n",
    "        if number_of_points == 0:\n",
    "            print(ordered_probs, prob_of_label_1_test)\n",
    "      \n",
    "        predicted_max_pki = set()\n",
    "        for key, item in ordered_probs.items():\n",
    "            if item <= max_rank:\n",
    "                predicted_max_pki.add(key)\n",
    "       \n",
    "        true_max_pki = set(y_test_ex_regr.sort_values(by = 'pKi', ascending=False).index[:number_of_points])\n",
    "       \n",
    "        try:\n",
    "            results.append([iteration, len(true_max_pki.intersection(predicted_max_pki))/number_of_points, number_of_points/y_test_ex.shape[0]])\n",
    "        except ZeroDivisionError:\n",
    "            results.append([iteration, 0, number_of_points/y_test_ex.shape[0]])\n",
    "       \n",
    "       \n",
    "        iteration += 1 \n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1526e38d-78d4-42f1-96fa-60ccf0688117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_new_func(datasets):\n",
    "    results = defaultdict(dict)\n",
    "    for dataset in tqdm(datasets):\n",
    "        for i in tqdm(range(0, 5)): \n",
    "            result_for_iteration = defaultdict(dict)\n",
    "            for method in tqdm(['abs', 'squared']): \n",
    "                if method == 'abs':\n",
    "                    end = 1.1\n",
    "                else:\n",
    "                    end = 1.0\n",
    "                for c in tqdm([0.0, 0.5, 0.7, end]):   \n",
    "                    result_for_iteration[method][c] = EF_new_func(dataset, method, c)\n",
    "                results[dataset][i] = result_for_iteration\n",
    "                with open(f'new_results/results_new_function_EF_worst_{dataset}.pickle', 'wb') as f:\n",
    "                        pickle.dump(results, f)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37e84f4-1674-44d9-ac97-6282e985c6bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def EF_class_on_all_dataset(dataset):\n",
    "    data = []\n",
    "    with open(f'x_and_y/{dataset}.pickle', \"rb\") as f:\n",
    "        for _ in range(pickle.load(f)):\n",
    "            data.append(pickle.load(f))\n",
    "  \n",
    "    x_train_ex, x_test_ex, y_test_ex_regr, y_train_ex, y_test_ex = data[0], data[1], data[3], data[4], data[5]\n",
    "    rfc = RandomForestClassifier(random_state=42, n_estimators=500, max_features='log2', n_jobs=20)\n",
    "    rfc.fit(x_train_ex.values, y_train_ex['activity'].values)\n",
    "    pred_ex = rfc.predict(x_test_ex.values)\n",
    "    proba_ex = rfc.predict_proba(x_test_ex.values)\n",
    "        \n",
    "    prob_of_label_1_test = []\n",
    "    for n, prob in enumerate(proba_ex):\n",
    "        prob_of_label_1_test.append([x_test_ex.index[n], prob[1]])\n",
    "\n",
    "\n",
    "    ordered_probs = dict()\n",
    "    ranked_probs = rankdata(prob_of_label_1_test, method='dense', axis=0)\n",
    "    max_rank = np.amax(ranked_probs, axis = 0)[1]\n",
    "    for i in ranked_probs:\n",
    "        i[1] = max_rank - i[1]\n",
    "\n",
    "    for n, el in enumerate(prob_of_label_1_test):\n",
    "        ordered_probs[el[0]] = ranked_probs[n][1]\n",
    "\n",
    "    number_of_points = 0\n",
    "    for rank in range (max(list(ordered_probs.values()))):\n",
    "        while number_of_points < round(y_test_ex.shape[0] * 0.1):\n",
    "            number_of_points += list(ordered_probs.values()).count(rank)\n",
    "            max_rank = rank \n",
    "            break\n",
    "\n",
    "    predicted_max_pki = set()\n",
    "    for key, item in ordered_probs.items():\n",
    "        if item <= max_rank:\n",
    "            predicted_max_pki.add(key)\n",
    "    for el in prob_of_label_1_test:\n",
    "        if el[0] in predicted_max_pki:\n",
    "            print(el[1])\n",
    "\n",
    "    true_max_pki = set(y_test_ex_regr.sort_values(by = 'pKi', ascending=False).index[:number_of_points])\n",
    "    try:\n",
    "        results = [len(true_max_pki.intersection(predicted_max_pki))/number_of_points, number_of_points/y_test_ex.shape[0]]\n",
    "    except ZeroDivisionError:\n",
    "        results =  [0, number_of_points/y_test_ex.shape[0]]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7e0ecb6-b3e4-48aa-b915-7642af29de64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_class(best_or_worst_datasets):\n",
    "    result = defaultdict(dict)\n",
    "    for dataset in tqdm(selected_datasets[f'{best_or_worst_datasets}_ba']):\n",
    "        for i in tqdm(range(10)): \n",
    "            result_for_iteration = dict()\n",
    "            for method in tqdm(['exploration', 'exploitation', 'random', 'bernulli']):  \n",
    "                result_for_iteration[method] = EF_classification(dataset,method)\n",
    "            result[dataset][i] = result_for_iteration\n",
    "        with open(f'new_results/results_EF_for_{best_or_worst_datasets}_ba.pickle', 'wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a1c637-7b2d-42f1-b19e-2861a82c9e97",
   "metadata": {},
   "source": [
    "РЕГРЕССИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2c53746-e5d1-4c57-9817-f5354eb4d1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EF_regression(dataset, method):\n",
    "    data = []\n",
    "    with open(f'x_and_y/{dataset}.pickle', \"rb\") as f:\n",
    "        for _ in range(pickle.load(f)):\n",
    "            data.append(pickle.load(f))\n",
    "    x_train_ex, x_test_ex, y_train_ex, y_test_ex = data[0], data[1], data[2], data[3]\n",
    "    x_train_in, x_test_in, y_train_in, y_test_in = train_test_split(x_train_ex, y_train_ex, test_size=len(y_train_ex)-10)\n",
    "    results = []\n",
    "    iteration = 0\n",
    "    while y_train_in.shape[0] < y_train_ex.shape[0]:\n",
    "        \n",
    "        rfr = RandomForestRegressor(random_state=42, n_estimators=500, max_features='log2', n_jobs=20)\n",
    "        rfr.fit(x_train_in.values, y_train_in['pKi'].values)\n",
    "         \n",
    "        if method == 'exploitation':          \n",
    "            adding_points = exploitation(rfr, x_test_in)         \n",
    "        elif method == 'exploration':\n",
    "            adding_points = exploration(rfr, x_train_in, y_train_in, x_test_in)          \n",
    "        elif method == 'mixed 1:4':\n",
    "            adding_points = set(exploitation(rfr, x_test_in)[0:4] + exploration(rfr, x_train_in, y_train_in, x_test_in)[0:1])\n",
    "        elif method == 'mixed 2:3':\n",
    "            adding_points = set(exploitation(rfr, x_test_in)[0:3] + exploration(rfr, x_train_in, y_train_in, x_test_in)[0:2])\n",
    "        else:\n",
    "            try:\n",
    "                adding_points = random.sample(list(x_test_in.index), 5)\n",
    "            except ValueError:\n",
    "                adding_points = list(x_test_in.index)       \n",
    "        \n",
    "        for point in adding_points:\n",
    "            x_train_in, y_train_in = x_train_in.append(x_test_in.loc[point]), y_train_in.append(y_test_in.loc[point])\n",
    "            x_test_in, y_test_in = x_test_in.drop(point), y_test_in.drop(point)\n",
    "\n",
    "        pred_test = rfr.predict(x_test_ex.values)\n",
    "        pred_value_test = []\n",
    "        for n, pred in enumerate(pred_test):\n",
    "            pred_value_test.append([x_test_ex.index[n], pred])\n",
    "              \n",
    "        ordered_preds = dict()\n",
    "        ranked_preds = rankdata(pred_value_test, method='dense', axis=0)\n",
    "        max_rank = np.amax(ranked_preds, axis = 0)[1]\n",
    "        for i in ranked_preds:\n",
    "            i[1] = max_rank - i[1]\n",
    "        for n, el in enumerate(pred_value_test):\n",
    "            ordered_preds[el[0]] = ranked_preds[n][1]\n",
    "           \n",
    "        number_of_points = 0\n",
    "        for rank in range (max(list(ordered_preds.values()))):\n",
    "            while number_of_points < round(y_test_ex.shape[0] * 0.1):\n",
    "                number_of_points += list(ordered_preds.values()).count(rank)\n",
    "                max_rank = rank \n",
    "                break       \n",
    "      \n",
    "        predicted_max_pki = set()\n",
    "        for key, item in ordered_preds.items():\n",
    "            if item <= max_rank:\n",
    "                predicted_max_pki.add(key)\n",
    "       \n",
    "        true_max_pki = set(y_test_ex.sort_values(by = 'pKi', ascending=False).index[:number_of_points])    \n",
    "        try:\n",
    "            results.append([iteration, len(true_max_pki.intersection(predicted_max_pki))/number_of_points, number_of_points/y_test_ex.shape[0]])\n",
    "        except ZeroDivisionError:\n",
    "            results.append([iteration, 0, number_of_points/y_test_ex.shape[0]])\n",
    "      \n",
    "        iteration += 1 \n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "665b79a7-639f-40f8-8bf6-c5ad78b163e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploitation(regressor, x_test_in):\n",
    "    pred_in = regressor.predict(x_test_in.values)      \n",
    "    pred_values = []\n",
    "    for n, value in enumerate(pred_in):\n",
    "        pred_values.append([x_test_in.index[n], value])\n",
    "    adding_points = [x[0] for x in sorted(pred_values, key=lambda x: x[1], reverse=True)][:5]\n",
    "    return adding_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "687c00fd-45cc-47e9-b36f-13ecea8593bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploration(regressor, x_train_in, y_train_in, x_test_in):\n",
    "    results_expl = dict()\n",
    "    for n in range(7):\n",
    "        x_bootsrap, y_bootstrap = resample(x_train_in, y_train_in, replace=True)\n",
    "        results_expl[n] = regressor.predict(x_test_in.values)\n",
    "    df = pd.DataFrame(results_expl)\n",
    "    df.index = x_test_in.index\n",
    "    df = df.T\n",
    "    adding_points = list(df.var().nlargest(5).index)\n",
    "    return adding_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a3218e46-c072-4111-8051-f4f00a6480b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EF_regression_on_all_dataset(dataset):\n",
    "    data = []  \n",
    "    with open(f'x_and_y/{dataset}.pickle', \"rb\") as f:\n",
    "        for _ in range(pickle.load(f)):\n",
    "            data.append(pickle.load(f))\n",
    "    x_train_ex, x_test_ex, y_train_ex, y_test_ex = data[0], data[1], data[2], data[3]\n",
    "    rfr = RandomForestRegressor(random_state=42, n_estimators=500, max_features='log2', n_jobs=20)\n",
    "    rfr.fit(x_train_ex.values, y_train_ex['pKi'].values)\n",
    "\n",
    "    pred_test = rfr.predict(x_test_ex.values)\n",
    "    pred_value_test = []\n",
    "    for n, pred in enumerate(pred_test):\n",
    "        pred_value_test.append([x_test_ex.index[n], pred])\n",
    "\n",
    "    ordered_preds = dict()\n",
    "    ranked_preds = rankdata(pred_value_test, method='dense', axis=0)\n",
    "    max_rank = np.amax(ranked_preds, axis = 0)[1]\n",
    "    for i in ranked_preds:\n",
    "        i[1] = max_rank - i[1]\n",
    "    for n, el in enumerate(pred_value_test):\n",
    "        ordered_preds[el[0]] = ranked_preds[n][1]\n",
    "\n",
    "\n",
    "    number_of_points = 0\n",
    "    for rank in range (max(list(ordered_preds.values()))):\n",
    "        while number_of_points < round(y_test_ex.shape[0] * 0.1):\n",
    "            number_of_points += list(ordered_preds.values()).count(rank)\n",
    "            max_rank = rank \n",
    "            break\n",
    "    \n",
    "    if number_of_points == 0:\n",
    "        print(ordered_preds, pred_value_test)\n",
    "\n",
    "    predicted_max_pki = set()\n",
    "    for key, item in ordered_preds.items():\n",
    "        if item <= max_rank:\n",
    "            predicted_max_pki.add(key)\n",
    "    true_max_pki = set(y_test_ex.sort_values(by = 'pKi', ascending=False).index[:number_of_points])\n",
    "    try:\n",
    "        results = [len(true_max_pki.intersection(predicted_max_pki))/number_of_points, number_of_points/y_test_ex.shape[0]]\n",
    "    except ZeroDivisionError:\n",
    "        results = [ 0, number_of_points/y_test_ex.shape[0]]\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10fe18ad-b91f-4fcd-b350-d9671362544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_regr(best_or_worst_datasets):\n",
    "    result = defaultdict(dict)\n",
    "    for dataset in tqdm(selected_datasets[f'{best_or_worst_datasets}_r2']):\n",
    "        for i in tqdm(range(10)): \n",
    "            result_for_iteration = dict()\n",
    "            for method in tqdm(['exploration', 'exploitation', 'random']):  \n",
    "                result_for_iteration[method] = EF_regression(dataset,method)\n",
    "            result[dataset][i] = result_for_iteration\n",
    "        with open(f'new_results/new_results_EF_for_{best_or_worst_datasets}_r2.pickle', 'wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ilnura)",
   "language": "python",
   "name": "ilnura"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
