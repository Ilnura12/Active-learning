{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "213fed32-72a8-4350-a929-5ee2b23bdfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from sklearn.metrics import mean_squared_error, r2_score, balanced_accuracy_score, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad4d7771-05bd-4290-b214-107b1bdc238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/selected_datasets.pickle', 'rb') as f:\n",
    "    selected_datasets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00baa4fd-0782-471f-9c81-5fadaaa301db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_of_max_pki_class(dataset, method):\n",
    "    data = []\n",
    "    with open(f'x_and_y/{dataset}.pickle', \"rb\") as f:\n",
    "        for _ in range(pickle.load(f)):\n",
    "            data.append(pickle.load(f))\n",
    "    x_train_ex, x_test_ex, y_train_ex_regr, y_train_ex, y_test_ex = data[0], data[1], data[2], data[4], data[5]\n",
    "    x_train_in, x_test_in, y_train_in, y_test_in, = train_test_split(x_train_ex, y_train_ex, test_size=len(y_train_ex)-10)\n",
    "    max_pki_index = y_train_ex_regr[['pKi']].idxmax()[0]\n",
    "    max_pki = y_train_ex_regr[['pKi']].max()[0]\n",
    "               \n",
    "    if max_pki_index in y_train_in.index:\n",
    "        random_point = random.choice(list(x_test_in.index))\n",
    "        x_test_in, y_test_in = x_test_in.append(x_train_in.loc[max_pki_index]), y_test_in.append(y_train_in.loc[max_pki_index])\n",
    "        x_train_in, y_train_in = x_train_in.append(x_test_in.loc[random_point]), y_train_in.append(y_test_in.loc[random_point])              \n",
    "        x_train_in, y_train_in = x_train_in.drop(max_pki_index), y_train_in.drop(max_pki_index)\n",
    "        x_test_in, y_test_in = x_test_in.drop(random_point), y_test_in.drop(random_point)        \n",
    "    \n",
    "    iteration = 0\n",
    "    while True:\n",
    "        rfc = RandomForestClassifier(random_state=42, n_estimators=500, max_features='log2', n_jobs=20)\n",
    "        rfc.fit(x_train_in.values, y_train_in['activity'].values)\n",
    "        classes = set(y_train_in['activity'].values)\n",
    "        \n",
    "        probs = rfc.predict_proba(x_test_in.values)\n",
    "        probs_difference, prob_of_label_1, prob_bernulli = [], [], []\n",
    "        for n, prob in enumerate(probs):\n",
    "            try:\n",
    "                prob_bernulli.append([x_test_in.index[n], prob[1]*(1-prob[1])])\n",
    "                probs_difference.append([x_test_in.index[n], abs(prob[0]-prob[1])])\n",
    "                prob_of_label_1.append([x_test_in.index[n], prob[1]])\n",
    "            except IndexError:\n",
    "                probs_difference.append([x_test_in.index[n], 1])\n",
    "                prob_bernulli.append([x_test_in.index[n], 0])\n",
    "                if 1 in classes:\n",
    "                    prob_of_label_1.append([x_test_in.index[n], 1]) \n",
    "                else:\n",
    "                    prob_of_label_1.append([x_test_in.index[n], 0])\n",
    "\n",
    "        least_sure = [x[0] for x in sorted(probs_difference, key=lambda x: x[1], reverse=False)][:5]\n",
    "        most_sure = [x[0] for x in sorted(prob_of_label_1, key=lambda x: x[1], reverse=True)][:5]\n",
    "        least_sure_bernulli = [x[0] for x in sorted(prob_bernulli, key=lambda x: x[1], reverse=True)][:5]\n",
    "        if method == 'exploration':\n",
    "            adding_points = least_sure\n",
    "        elif method == 'exploitation':\n",
    "            adding_points = most_sure\n",
    "        elif method == 'bernulli':\n",
    "            adding_points = least_sure_bernulli\n",
    "        elif method == 'mixed 1:4':\n",
    "            adding_points = set(most_sure[0:4] + least_sure[0:1])\n",
    "        elif method == 'mixed 2:3':\n",
    "            adding_points = set(most_sure[0:3] + least_sure[0:2])\n",
    "        else:\n",
    "            try:\n",
    "                adding_points = random.sample(list(x_test_in.index), 5)\n",
    "            except ValueError:\n",
    "                adding_points = list(x_test_in.index)\n",
    "                \n",
    "        for point in adding_points:\n",
    "            x_train_in, y_train_in = x_train_in.append(x_test_in.loc[point]), y_train_in.append(y_test_in.loc[point])\n",
    "            x_test_in, y_test_in = x_test_in.drop(point), y_test_in.drop(point)\n",
    "        iteration += 1\n",
    "        if max_pki_index in adding_points:\n",
    "            iteration_of_max_pki = iteration\n",
    "            break\n",
    "\n",
    "    return iteration_of_max_pki, max_pki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93f0d1eb-8342-4f49-a8d1-f7026a382786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_class(best_or_worst_datasets):\n",
    "    result = defaultdict(dict)\n",
    "    for dataset in tqdm(selected_datasets[f'{best_or_worst_datasets}_ba']):\n",
    "        for i in tqdm(range(10)): \n",
    "            result_for_iteration = dict()\n",
    "            for method in tqdm(['exploration', 'exploitation', 'bernulli','random', 'mixed 1:4', 'mixed 2:3']):  \n",
    "                result_for_iteration[method] = search_of_max_pki_class(dataset,method)\n",
    "            result[dataset][i] = result_for_iteration\n",
    "        with open(f'new_results/new_searching_rank_for_{best_or_worst_datasets}_ba_in_intrnal_test.pickle', 'wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19c68f68-5bb5-4eb3-be0b-121916f55503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploration(regressor, x_train_in, y_train_in, x_test_in):\n",
    "    results_expl = dict()\n",
    "    for n in range(7):\n",
    "        x_bootsrap, y_bootstrap = resample(x_train_in, y_train_in, replace=True)\n",
    "        results_expl[n] = regressor.predict(x_test_in.values)\n",
    "    df = pd.DataFrame(results_expl)\n",
    "    df.index = x_test_in.index\n",
    "    df = df.T\n",
    "    adding_points = list(df.var().nlargest(5).index)\n",
    "    return adding_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4b3f962-7d4c-4096-a20c-5408437bfff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploitation(regressor, x_test_in):\n",
    "    pred_in = regressor.predict(x_test_in.values)      \n",
    "    pred_values = []\n",
    "    for n, value in enumerate(pred_in):\n",
    "        pred_values.append([x_test_in.index[n], value])\n",
    "    adding_points = [x[0] for x in sorted(pred_values, key=lambda x: x[1], reverse=True)][:5]\n",
    "    return adding_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71084f2c-efab-472d-b84c-0c010b71270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_of_max_pki_regr(dataset, method):\n",
    "    data = []\n",
    "    with open(f'x_and_y/{dataset}.pickle', \"rb\") as f:\n",
    "        for _ in range(pickle.load(f)):\n",
    "            data.append(pickle.load(f))\n",
    "  \n",
    "    x_train_ex, x_test_ex, y_train_ex, y_test_ex = data[0], data[1], data[2], data[3]\n",
    "    x_train_in, x_test_in, y_train_in, y_test_in, = train_test_split(x_train_ex, y_train_ex, test_size=len(y_train_ex)-10)\n",
    "    max_pki_index = y_train_ex[['pKi']].idxmax()[0]\n",
    "    max_pki = y_train_ex[['pKi']].max()[0]\n",
    "               \n",
    "    if max_pki_index in y_train_in.index:\n",
    "        random_point = random.choice(list(x_test_in.index))\n",
    "        x_test_in, y_test_in = x_test_in.append(x_train_in.loc[max_pki_index]), y_test_in.append(y_train_in.loc[max_pki_index])\n",
    "        x_train_in, y_train_in = x_train_in.append(x_test_in.loc[random_point]), y_train_in.append(y_test_in.loc[random_point])              \n",
    "        x_train_in, y_train_in = x_train_in.drop(max_pki_index), y_train_in.drop(max_pki_index)\n",
    "        x_test_in, y_test_in = x_test_in.drop(random_point), y_test_in.drop(random_point)        \n",
    "    \n",
    "    iteration = 0\n",
    "    while True:\n",
    "        rfr = RandomForestRegressor(random_state=42, n_estimators=500, max_features='log2', n_jobs=20)\n",
    "        rfr.fit(x_train_in.values, y_train_in['pKi'].values)\n",
    "        if method == 'exploitation':         \n",
    "            adding_points = exploitation(rfr, x_test_in)          \n",
    "\n",
    "        elif method == 'exploration':\n",
    "            adding_points = exploration(rfr, x_train_in, y_train_in, x_test_in)\n",
    "           \n",
    "        elif method == 'mixed 1:4':\n",
    "            adding_points = set(exploitation(rfr, x_test_in)[0:4] + exploration(rfr, x_train_in, y_train_in, x_test_in)[0:1])\n",
    "        elif method == 'mixed 2:3':\n",
    "            adding_points = set(exploitation(rfr, x_test_in)[0:3] + exploration(rfr, x_train_in, y_train_in, x_test_in)[0:2])\n",
    "        else:\n",
    "            try:\n",
    "                adding_points = random.sample(list(x_test_in.index), 5)\n",
    "            except ValueError:\n",
    "                adding_points = list(x_test_in.index)\n",
    "        for point in adding_points:\n",
    "            x_train_in, y_train_in = x_train_in.append(x_test_in.loc[point]), y_train_in.append(y_test_in.loc[point])\n",
    "            x_test_in, y_test_in = x_test_in.drop(point), y_test_in.drop(point)\n",
    "        \n",
    "        if max_pki_index in adding_points:\n",
    "            iteration_of_max_pki = iteration\n",
    "            break\n",
    "        iteration += 1\n",
    "       \n",
    "    return iteration_of_max_pki, max_pki\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54a618a1-bd2f-4d2b-a568-93aef325a87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_regr(best_or_worst_datasets):\n",
    "    result = defaultdict(dict)\n",
    "    for dataset in tqdm(selected_datasets[f'{best_or_worst_datasets}_r2']):\n",
    "        for i in tqdm(range(10)): \n",
    "            result_for_iteration = dict()\n",
    "            for method in tqdm(['exploration', 'exploitation', 'random', 'mixed 1:4', 'mixed 2:3']):  \n",
    "                result_for_iteration[method] = search_of_max_pki_regr(dataset,method)\n",
    "            result[dataset][i] = result_for_iteration\n",
    "        with open(f'results/results_searching_max_pki_for_{best_or_worst_datasets}_r2_in_internal_test.pickle', 'wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467fefc1-edcb-47ae-a278-239ac55e8d84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d26c64-6ef4-437a-b569-f3fa2ea3f0ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ilnura)",
   "language": "python",
   "name": "ilnura"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
