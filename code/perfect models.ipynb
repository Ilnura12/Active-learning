{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14b21f31-dab0-4796-b1de-2474bd9991d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import pandas as pd\n",
    "import os\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from sklearn.metrics import mean_squared_error, r2_score, balanced_accuracy_score, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "173bd0d3-37a3-418e-8d6d-b6ab67859f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/selected_datasets.pickle', 'rb') as f:\n",
    "    selected_datasets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31c511c6-2425-4a4a-bc43-d8a1e8d19ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_datasets = set(selected_datasets['best_ba']).intersection(selected_datasets['best_r2'])\n",
    "worst_datasets = set(selected_datasets['worst_ba']).intersection(selected_datasets['worst_r2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2c2a7be-2b95-499a-9d07-979ffd94a3f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def perfect_model_classification(dataset):\n",
    "    data = []\n",
    "    with open(f'x_and_y/{dataset}.pickle', \"rb\") as f:\n",
    "        for _ in range(pickle.load(f)):\n",
    "            data.append(pickle.load(f))\n",
    "    x_train_ex, x_test_ex, y_train_ex, y_test_ex = data[0], data[1], data[4], data[5]\n",
    "    x_train_in, x_test_in, y_train_in, y_test_in, = train_test_split(x_train_ex, y_train_ex, test_size=len(y_train_ex)-10)\n",
    "    len_of_dataset = len(x_train_ex) + len(x_test_ex)\n",
    "    results = []\n",
    "    iteration = 0\n",
    "    if len_of_dataset < 300:\n",
    "        number_of_points = 100\n",
    "    elif 300 <= len_of_dataset <= 600:\n",
    "        number_of_points = 300\n",
    "    else:\n",
    "        number_of_points = 500\n",
    "    \n",
    "    while len(y_train_in) < 150:\n",
    "        rfc = RandomForestClassifier(random_state=42, n_estimators=500, max_features='log2', n_jobs=20)\n",
    "        rfc.fit(x_train_in.values, y_train_in['activity'].values)\n",
    "        classes = set(y_train_in['activity'].values)\n",
    "\n",
    "        pred = rfc.predict(x_test_ex.values)\n",
    "        proba = rfc.predict_proba(x_test_ex.values)\n",
    "        if len(classes) == 1:\n",
    "            if 1 in classes:\n",
    "                proba = np.insert(proba, 0, 0, axis = 1)\n",
    "            else:\n",
    "                proba = np.insert(proba, 1, 0, axis = 1)\n",
    "        ba = balanced_accuracy_score(y_test_ex.values, pred)\n",
    "        fpr, tpr, _ = roc_curve(y_test_ex.values, [x[1] for x in proba])\n",
    "        AUC = auc(fpr, tpr)\n",
    "        results.append([iteration, ba, AUC])\n",
    "        \n",
    "        try:\n",
    "            adding_points = random.sample(list(x_test_in.index), number_of_points)\n",
    "        except ValueError:\n",
    "            adding_points = list(x_test_in.index)\n",
    "        \n",
    "        results_of_iteration = []\n",
    "\n",
    "        for point in adding_points:\n",
    "            x_train_in, y_train_in = x_train_in.append(x_test_in.loc[point]), y_train_in.append(y_test_in.loc[point])\n",
    "            x_test_in, y_test_in = x_test_in.drop(point), y_test_in.drop(point)        \n",
    "            rfc = RandomForestClassifier(random_state=42, n_estimators=500, max_features='log2', n_jobs=20)\n",
    "            rfc.fit(x_train_in.values, y_train_in['activity'].values)      \n",
    "            pred = rfc.predict(x_test_in.values)\n",
    "            ba = balanced_accuracy_score(y_test_in['activity'].values, pred)       \n",
    "            results_of_iteration.append([point, ba])\n",
    "            x_test_in, y_test_in = x_test_in.append(x_train_in.loc[point]), y_test_in.append(y_train_in.loc[point])\n",
    "            x_train_in, y_train_in = x_train_in.drop(point), y_train_in.drop(point) \n",
    "          \n",
    "        best_point = sorted(results_of_iteration, key=lambda x: x[1], reverse=True)[0][0]\n",
    "\n",
    "        x_train_in, y_train_in = x_train_in.append(x_test_in.loc[best_point]), y_train_in.append(y_test_in.loc[best_point])\n",
    "        x_test_in, y_test_in = x_test_in.drop(best_point), y_test_in.drop(best_point) \n",
    "        appended_points = list(x_train_in.index)\n",
    "        iteration += 1\n",
    "    return results, appended_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1942672-1112-4966-aac5-c979855c795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfect_model_regression(dataset):\n",
    "    data = []\n",
    "    with open(f'x_and_y/{dataset}.pickle', \"rb\") as f:\n",
    "        for _ in range(pickle.load(f)):\n",
    "            data.append(pickle.load(f))\n",
    "    x_train_ex, x_test_ex, y_train_ex, y_test_ex = data[0], data[1], data[2], data[3]\n",
    "    x_train_in, x_test_in, y_train_in, y_test_in, = train_test_split(x_train_ex, y_train_ex, test_size=len(y_train_ex)-10)\n",
    "    len_of_dataset = len(x_train_ex) + len(x_test_ex)\n",
    "    results = []\n",
    "    iteration = 0\n",
    "    if len_of_dataset < 300:\n",
    "        number_of_points = 100\n",
    "    elif 300 <= len_of_dataset <= 600:\n",
    "        number_of_points = 300\n",
    "    else:\n",
    "        number_of_points = 500\n",
    "\n",
    "    while len(y_train_in) < 150:\n",
    "        rfr_ex = RandomForestRegressor(random_state=42, n_estimators=500, max_features='log2', n_jobs=20)\n",
    "        rfr_ex.fit(x_train_in.values, y_train_in['pKi'].values)\n",
    "        \n",
    "        pred_ex = rfr_ex.predict(x_test_ex.values)        \n",
    "        r2_ex = r2_score(y_test_ex.values, pred_ex)\n",
    "        rmse = mean_squared_error(y_test_ex.values, pred_ex, squared=False)\n",
    "        \n",
    "        results.append([iteration, r2_ex, rmse])\n",
    "\n",
    "        try:\n",
    "            adding_points = random.sample(list(x_test_in.index), number_of_points)\n",
    "        except ValueError:\n",
    "            adding_points = list(x_test_in.index)\n",
    "        results_of_iteration = []\n",
    "\n",
    "        for point in adding_points:\n",
    "            x_train_in, y_train_in = x_train_in.append(x_test_in.loc[point]), y_train_in.append(y_test_in.loc[point])\n",
    "            x_test_in, y_test_in = x_test_in.drop(point), y_test_in.drop(point)        \n",
    "            rfr = RandomForestRegressor(random_state=42, n_estimators=500, max_features='log2', n_jobs=20)\n",
    "            rfr.fit(x_train_in.values, y_train_in['pKi'].values)\n",
    "            pred = rfr.predict(x_test_in.values)\n",
    "            r2 = r2_score(y_test_in.values, pred) \n",
    "            results_of_iteration.append([point, r2])\n",
    "            x_test_in, y_test_in = x_test_in.append(x_train_in.loc[point]), y_test_in.append(y_train_in.loc[point])\n",
    "            x_train_in, y_train_in = x_train_in.drop(point), y_train_in.drop(point) \n",
    "          \n",
    "        best_point = sorted(results_of_iteration, key=lambda x: x[1], reverse=True)[0][0]\n",
    "\n",
    "        x_train_in, y_train_in = x_train_in.append(x_test_in.loc[best_point]), y_train_in.append(y_test_in.loc[best_point])\n",
    "        x_test_in, y_test_in = x_test_in.drop(best_point), y_test_in.drop(best_point) \n",
    "        appended_points = list(x_train_in.index)\n",
    "        iteration += 1\n",
    "    return results, appended_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c1063bc-cf78-4fbf-ad00-e29eefadbe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_class(datasets):\n",
    "    result = defaultdict(dict)\n",
    "    for dataset in tqdm(datasets):\n",
    "        result[dataset] = perfect_model_classification(dataset)  \n",
    "        with open(f'new_results/perfect_model_class_{dataset}.pickle', 'wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d53998-d9ba-4628-a8c2-61a8ff5a09c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_regr(datasets):\n",
    "    result = defaultdict(dict)\n",
    "    for dataset in tqdm(datasets):\n",
    "        result[dataset] = perfect_model_regression(dataset)  \n",
    "        with open(f'new_results/perfect_model_regr_{dataset}.pickle', 'wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ilnura)",
   "language": "python",
   "name": "ilnura"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
